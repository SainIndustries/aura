---
phase: 06-async-pipeline-foundation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/lib/db/schema.ts
  - src/lib/provisioning/queue.ts
autonomous: true

must_haves:
  truths:
    - "Provisioning job can be created in database with status 'queued'"
    - "Only one provisioning job per user can be in-progress at a time"
    - "Job status transitions are atomic (no race conditions)"
    - "Stale job detection works via heartbeat timeout"
  artifacts:
    - path: "src/lib/db/schema.ts"
      provides: "provisioningJobs table definition with jobStatusEnum"
      contains: "provisioningJobs"
    - path: "src/lib/provisioning/queue.ts"
      provides: "Job queue operations: enqueue, update status, check concurrent, check timeout"
      exports: ["enqueueProvisioningJob", "updateJobStatus", "checkConcurrentProvision", "checkJobTimeout"]
  key_links:
    - from: "src/lib/provisioning/queue.ts"
      to: "src/lib/db/schema.ts"
      via: "imports provisioningJobs table"
      pattern: "import.*provisioningJobs.*from.*schema"
---

<objective>
Create the provisioning jobs database table and job queue operations module.

Purpose: Establish the data foundation for the async pipeline. The `provisioning_jobs` table is the source of truth for all provisioning operations. The queue module provides atomic operations for job creation, status updates, concurrency control, and timeout detection.

Output: Database schema with `provisioning_jobs` table and `src/lib/provisioning/queue.ts` module with queue operations.
</objective>

<execution_context>
@/Users/danielhuynh/.claude/get-shit-done/workflows/execute-plan.md
@/Users/danielhuynh/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-async-pipeline-foundation/06-RESEARCH.md
@src/lib/db/schema.ts
@src/lib/provisioning/index.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add provisioning_jobs table to database schema</name>
  <files>src/lib/db/schema.ts</files>
  <action>
Add a new `jobStatusEnum` pgEnum and `provisioningJobs` pgTable to the existing schema file.

**Enum definition:**
```typescript
export const jobStatusEnum = pgEnum("job_status", [
  "queued",
  "provisioning",
  "running",
  "failed",
]);
```

**Table definition — `provisioningJobs`:**
- `id`: uuid, defaultRandom, primaryKey
- `agentId`: uuid, references agents.id (onDelete: cascade), notNull
- `userId`: uuid, references users.id (onDelete: cascade), notNull
- `stripeEventId`: text, unique (for idempotency — prevents duplicate jobs on Stripe webhook retry)
- `status`: jobStatusEnum, notNull, default "queued"
- `region`: text, notNull, default "us-east"
- `workflowRunId`: text, nullable (GitHub Actions run ID, posted back via callback)
- `retryCount`: integer, notNull, default 0
- `maxRetries`: integer, notNull, default 3 (user decision: 3-5 attempts, using 3 as default)
- `error`: text, nullable (error message on failure)
- `failedStep`: text, nullable (which pipeline step failed — for debugging)
- `claimedAt`: timestamp with timezone, nullable (when job was picked up for processing)
- `lastHeartbeatAt`: timestamp with timezone, nullable (last heartbeat from GitHub Actions)
- `completedAt`: timestamp with timezone, nullable (when job reached terminal state)
- `createdAt`: timestamp with timezone, defaultNow, notNull
- `updatedAt`: timestamp with timezone, defaultNow, notNull

**Relations:**
Add `provisioningJobsRelations` using Drizzle `relations()`:
- `agent`: one-to-one with agents table (fields: [provisioningJobs.agentId], references: [agents.id])
- `user`: one-to-one with users table (fields: [provisioningJobs.userId], references: [users.id])

Also update `usersRelations` to include `provisioningJobs: many(provisioningJobs)` and `agentsRelations` to include `provisioningJobs: many(provisioningJobs)`.

**Important:** Place the enum before the table definition. Place the table after `agentInstances`. Follow existing schema patterns exactly (same import style, same timestamp patterns, same relation patterns).

After modifying schema.ts, generate a Drizzle migration:
```bash
npx drizzle-kit generate
```

This creates a SQL migration file in `./drizzle/` directory. Do NOT run `drizzle-kit push` (that requires database access).
  </action>
  <verify>
1. `npx tsc --noEmit` passes without type errors
2. `npx drizzle-kit generate` creates a migration file in `./drizzle/`
3. The migration SQL contains `CREATE TABLE "provisioning_jobs"` and `CREATE TYPE "public"."job_status"`
  </verify>
  <done>
provisioningJobs table defined in schema.ts with all columns, jobStatusEnum enum, relations to users and agents, and a Drizzle migration file generated.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create job queue operations module</name>
  <files>src/lib/provisioning/queue.ts</files>
  <action>
Create `src/lib/provisioning/queue.ts` with the following exported functions:

**Constants (top of file):**
```typescript
// Heartbeat interval: 60 seconds (GitHub Actions posts heartbeat every 60s)
export const HEARTBEAT_INTERVAL_SECONDS = 60;
// Job timeout: 15 minutes (conservative — VM creation ~2-3min + Ansible ~3-5min + buffer)
export const JOB_TIMEOUT_SECONDS = 900;
// Max retries before requiring support intervention
export const MAX_RETRIES = 3;
```

**1. `enqueueProvisioningJob(params)`:**
- Parameters: `{ agentId: string, userId: string, stripeEventId: string, region?: string }`
- Returns: `Promise<typeof provisioningJobs.$inferSelect>`
- Logic:
  - First call `checkConcurrentProvision(userId)` — throws if user has in-progress job
  - Insert into `provisioningJobs` with status "queued", retryCount 0
  - Return the inserted row
- This function does NOT trigger GitHub Actions (that's Plan 02's responsibility)

**2. `checkConcurrentProvision(userId)`:**
- Parameters: `userId: string`
- Returns: `Promise<void>` (throws if concurrent job exists)
- Logic:
  - Query `provisioningJobs` for rows where userId matches AND status IN ("queued", "provisioning")
  - If found, throw `Error` with message: `"A provisioning job is already in progress. Please wait for it to complete."`
  - Per user decision: one provision at a time per user

**3. `updateJobStatus(params)`:**
- Parameters: `{ jobId: string, status: "queued" | "provisioning" | "running" | "failed", workflowRunId?: string, error?: string, failedStep?: string }`
- Returns: `Promise<typeof provisioningJobs.$inferSelect>`
- Logic:
  - Update the job row with provided fields + `updatedAt: new Date()`
  - If status is "running" or "failed", also set `completedAt: new Date()`
  - If status is "provisioning", set `claimedAt: new Date()`
  - Return the updated row via `.returning()`

**4. `recordHeartbeat(jobId)`:**
- Parameters: `jobId: string`
- Returns: `Promise<void>`
- Logic:
  - Update `lastHeartbeatAt` to `new Date()` and `updatedAt` to `new Date()`
  - Where `id = jobId` AND `status = "provisioning"` (only heartbeat active jobs)

**5. `checkJobTimeout(jobId)`:**
- Parameters: `jobId: string`
- Returns: `Promise<boolean>` (true if timed out and marked failed)
- Logic:
  - Fetch job by ID
  - If job not found or status is not "provisioning", return false
  - Calculate seconds since `lastHeartbeatAt` (or `claimedAt` if no heartbeat yet, or `updatedAt` as last resort)
  - If elapsed > `JOB_TIMEOUT_SECONDS` (900s / 15 min):
    - Update status to "failed", set error to `"Timeout: No heartbeat for {N}s"`, set `completedAt`
    - Return true
  - Otherwise return false
- Per user decision: on-demand stale job detection (called when dashboard checks status)

**6. `getJobByStripeEventId(stripeEventId)`:**
- Parameters: `stripeEventId: string`
- Returns: `Promise<typeof provisioningJobs.$inferSelect | undefined>`
- Logic: Simple query by stripeEventId for idempotency check

**7. `getJobByAgentId(agentId)`:**
- Parameters: `agentId: string`
- Returns: `Promise<typeof provisioningJobs.$inferSelect | undefined>`
- Logic: Get most recent job for agent (ordered by createdAt desc, limit 1)

Import `db` from `@/lib/db`, import `provisioningJobs` from `@/lib/db/schema`, import `eq`, `and`, `or`, `desc` from `drizzle-orm`.

Use `crypto.timingSafeEqual` is NOT needed here (that's for HMAC in Plan 03). Standard equality checks are fine for database queries.

Follow existing codebase conventions: named exports, camelCase functions, console.log with `[Queue]` prefix for logging, throw Error for failures.
  </action>
  <verify>
1. `npx tsc --noEmit` passes without type errors
2. All 7 functions are exported from `src/lib/provisioning/queue.ts`
3. File imports use `@/` alias paths
  </verify>
  <done>
queue.ts module exports enqueueProvisioningJob, checkConcurrentProvision, updateJobStatus, recordHeartbeat, checkJobTimeout, getJobByStripeEventId, and getJobByAgentId. All functions use proper Drizzle queries against the provisioningJobs table.
  </done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` — full project compiles without type errors
2. Drizzle migration file exists in `./drizzle/` for the new table
3. `src/lib/provisioning/queue.ts` is importable and exports all 7 functions
</verification>

<success_criteria>
- provisioningJobs table schema defined with all columns matching research spec
- jobStatusEnum has exactly 4 states: queued, provisioning, running, failed
- Queue module provides atomic job operations with concurrency control
- Heartbeat timeout detection works with 15-minute threshold
- Drizzle migration generated for the new table
</success_criteria>

<output>
After completion, create `.planning/phases/06-async-pipeline-foundation/06-01-SUMMARY.md`
</output>
